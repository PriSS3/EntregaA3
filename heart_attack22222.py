# -*- coding: utf-8 -*-
"""Heart Attack22222

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KzD7RSFFgp8tN17Rx5i3-B7Yk_LfpORS
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("redwankarimsony/heart-disease-data")

print("Path to dataset files:", path)

#pandas: Para manipulação e análise de dados.
#os: Para interagir com o sistema de arquivos.
#matplotlib.pyplot: Para visualização de gráficos.
#sklearn.model_selection: Para dividir os dados em conjuntos de treino e teste e realizar busca em grade.
#sklearn.tree: Para usar o classificador de árvore de decisão.
#sklearn.metrics: Para avaliar o desempenho do modelo.
#yellowbrick.classifier: Para visualização da matriz de confusão.

import pandas as pd
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from yellowbrick.classifier import ConfusionMatrix

#Exibe o caminho para os arquivos do conjunto de dados e lista os arquivos disponíveis nesse diretório.
print("Path to dataset files:", path)
files = os.listdir(path)
print("Arquivos disponíveis:", files)

# Carregar o dataset
df = pd.read_csv(os.path.join(path, files[0]))

#LIMPEZA E NORMALIZAÇÃO

#colunas retiradas com muitos valores nulos e irrelevantes
df.drop(['id', 'ca'], axis=1, inplace=True)

#verificação de duplicatas
df.drop_duplicates(inplace=True)
duplicates = df.duplicated().sum()
print(f"Número de duplicatas: {duplicates}")

#preenche valores nulos em várias colunas com a mediana ou média apropriada, ou um valor padrão (como 'False' ou 'normal').
df.trestbps=df.trestbps.fillna(df['trestbps'].median())

df.chol=df.chol.fillna(df['chol'].median())

df.fbs=df.fbs.fillna('False')

df.restecg=df.restecg.fillna('normal')

df.thalch=df.thalch.fillna(df['thalch'].mean())

df.exang=df.exang.fillna('False')

df.oldpeak=df.oldpeak.fillna(df['oldpeak'].mean())

df.slope=df.slope.fillna('flat')

#Prepara os dados pra modelagem, coluna alvo
X = df.drop('num', axis='columns')

#Agrupa algumas classes na variável alvo para simplificar a classificação
df.loc[df["num"] == 2,"num"]=1
df.loc[df["num"] ==3,"num"]=1
df.loc[df["num"] ==4,"num"]=1
y = df['num']

#identificação de colunas categóricas
colunas_categoricas = df.select_dtypes(include=['object', 'category']).columns.tolist()
print("Colunas categóricas:", colunas_categoricas)

#Converte variáveis categóricas em variáveis indicadoras para que possam ser usadas no modelo e evitar problema de multicolinearidade
df = pd.get_dummies(df, columns=['sex', 'slope', 'cp', 'fbs', 'restecg', 'exang', 'thal', 'dataset'], drop_first=True)
X = df.drop('num', axis='columns')

df_columns = df.columns.tolist()
print("Colunas do DataFrame:", df_columns)

#ÁRVORE DE DECISÃO

#Divide os dados em conjuntos de treinamento (80%) e teste (20%).
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

# Definir o modelo de árvore de decisão, criando uma instância
model = DecisionTreeClassifier(random_state=0)
#--------------------------------------------------------------------------------------------------------------------------------------
# Definir os hiperparâmetros a serem ajustados que serão testados durante a busca em grade. Uma lista de diferentes opções para ajustar o modelo
#criterion: Define a função de avaliação da qualidade da divisão. As opções 'gini' e 'entropy' são comuns em árvores de decisão.
#max_depth: Limita a profundidade da árvore. Um valor None significa que não há limite, enquanto valores entre 1 e 10 controlam a complexidade da árvore.
#min_samples_split: O número mínimo de amostras necessárias para dividir um nó interno. Valores maiores podem levar a árvores mais simples.
#min_samples_leaf: O número mínimo de amostras que deve estar presente em um nó folha. Isso ajuda a evitar o sobreajuste.
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None] + list(range(1, 11)),
    'min_samples_split': [2] + list(range(3, 11)),
    'min_samples_leaf': [1] + list(range(2, 11))
}

# Configurar a validação cruzada com GridSearchCV para encontrar a melhor combinação testando combinações desses hiperparâmetros

#estimator: O modelo que você deseja otimizar.
#param_grid: Um dicionário que contém os hiperparâmetros e suas respectivas opções.
#scoring: A métrica usada para avaliar a performance do modelo (neste caso, acurácia).
#cv: O número de folds para a validação cruzada; neste exemplo, é utilizado 5.
#n_jobs: Define quantos núcleos do processador usar; -1 usa todos os núcleos disponíveis.
#verbose: Controla a quantidade de informações impressas durante o processo de ajuste; 1 fornece atualizações sobre o progresso.

grid_search = GridSearchCV(estimator=model,param_grid=param_grid,
scoring='accuracy', cv=5, n_jobs=-1, verbose=1)

# Ajustar o modelo aos dados de treinamento usando GridSearchCV
grid_search.fit(X_train, y_train)

# Obter os melhores parâmetros encontrados
best_params = grid_search.best_params_
print("Melhores parâmetros encontrados:", best_params)

# Fazer previsões no conjunto de teste usando o melhor modelo encontrado
y_pred = grid_search.predict(X_test)

# Acessar os resultados
results = grid_search.cv_results_

# Facilitar a visualização
results_df = pd.DataFrame(results)

# Exibir as colunas relevantes
#params: Os hiperparâmetros testados.
#mean_test_score: A média da pontuação (neste caso, acurácia) para cada combinação de hiperparâmetros.
#std_test_score: O desvio padrão das pontuações, que fornece uma ideia da variabilidade dos resultados
print(results_df[['params', 'mean_test_score', 'std_test_score']])

#----------------------------------------------------------------------------------------------------------------
# Avaliar o modelo ajustado
accuracy = accuracy_score(y_test, y_pred)
print("Acurácia do modelo:", accuracy)

# Criar a matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusão:\n", conf_matrix)

# Imprimir o relatório de classificação
report = classification_report(y_test, y_pred)
print("Relatório de Classificação:\n", report)

#Visualizar a matriz de confusão usando Yellowbrick
cm_visualizer = ConfusionMatrix(grid_search.best_estimator_)
cm_visualizer.fit(X_train, y_train)
cm_visualizer.score(X_test, y_test)

# Adicionando título à visualização da matriz de confusão
plt.title("Matriz de Confusão")
plt.show()